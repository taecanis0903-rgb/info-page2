import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import time
import pandas as pd
import datetime
import os
import re

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---

# ì±—ë´‡ ì œëª© ë° í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë°©íƒˆì¶œ ì•± ê³ ê° ë¶ˆí¸ ì‘ëŒ€ AI ì±—ë´‡",
    layout="wide"
)
st.title("ğŸ¤– ë°©íƒˆì¶œ ì•± ê³ ê° ë¶ˆí¸ ì‘ëŒ€ AI ì±—ë´‡")
st.caption("Gemini API (ëª¨ë¸: gemini-2.0-flash) í™œìš©")

# Streamlit secretsì—ì„œ API í‚¤ ë¡œë“œ ë˜ëŠ” ì„ì‹œ ì…ë ¥ UI ì œê³µ
def get_api_key():
    """API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. st.secretsì—ì„œ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤."""
    try:
        # 1. st.secretsì—ì„œ í‚¤ ë¡œë“œ ì‹œë„
        api_key = st.secrets["GEMINI_API_KEY"]
        st.sidebar.success("API Key ë¡œë“œ ì™„ë£Œ (st.secrets)")
        return api_key
    except (KeyError, AttributeError):
        # 2. st.secretsì— í‚¤ê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ UI í‘œì‹œ
        st.sidebar.warning("`st.secrets['GEMINI_API_KEY']`ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        user_key = st.sidebar.text_input(
            "Gemini API Key ì…ë ¥",
            type="password",
            placeholder="AI Studio ë˜ëŠ” Google Cloudì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
        )
        if user_key:
            return user_key
        return None

GEMINI_API_KEY = get_api_key()

# API í‚¤ê°€ ì—†ìœ¼ë©´ ì•± ì‹¤í–‰ ì¤‘ë‹¨
if not GEMINI_API_KEY:
    st.info("Gemini API í‚¤ë¥¼ ì œê³µí•´ì•¼ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# ëª¨ë¸ ì„¤ì • (ì„ íƒ ê°€ëŠ¥ ëª©ë¡ ë° ê¸°ë³¸ê°’)
AVAILABLE_MODELS = ["gemini-2.0-flash", "gemini-2.5-flash", "gemini-2.0-pro", "gemini-2.5-pro"]
DEFAULT_MODEL = "gemini-2.0-flash"

# Sidebar: ëª¨ë¸ ì„ íƒ, ë¡œê·¸ ê¸°ë¡ ì˜µì…˜, ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •")
    selected_model = st.selectbox(
        "ì‚¬ìš©í•  Gemini ëª¨ë¸ ì„ íƒ (gemini-2.0-flash ê¸°ë³¸)",
        options=AVAILABLE_MODELS,
        index=AVAILABLE_MODELS.index(DEFAULT_MODEL) if DEFAULT_MODEL in AVAILABLE_MODELS else 0,
        key="model_select"
    )
    
    # CSV ìë™ ê¸°ë¡ ì˜µì…˜
    if 'log_to_csv' not in st.session_state:
        st.session_state.log_to_csv = False
        
    st.session_state.log_to_csv = st.checkbox("ëŒ€í™” ë‚´ìš© CSV ìë™ ê¸°ë¡", value=st.session_state.log_to_csv)
    
    st.markdown("---")
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", help="í˜„ì¬ ëŒ€í™” ë‚´ìš©ì„ ëª¨ë‘ ì§€ì›ë‹ˆë‹¤."):
        st.session_state.messages = []
        st.session_state.chat = initialize_chat_session(GEMINI_API_KEY, selected_model)
        st.session_state.history_reset_count = 0
        st.success("ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ 'ë°©íƒˆì¶œ' ì–´í”Œë¦¬ì¼€ì´ì…˜ì˜ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ ê³ ê° ì‘ëŒ€ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ìëŠ” ì–´í”Œ ì‚¬ìš© ì¤‘ (ì˜ˆ: ê²°ì œ ì˜¤ë¥˜, ë²„ê·¸, ì˜ˆì•½ ë¬¸ì œ, ê²Œì„ ì§„í–‰ ë¶ˆí¸ ë“±) ê²ªì€ ë¶ˆí¸/ë¶ˆë§Œì„ ì–¸ê¸‰í•©ë‹ˆë‹¤.
ë‹¤ìŒ ì§€ì¹¨ì„ **ì—„ê²©í•˜ê²Œ** ë”°ë¥´ì„¸ìš”:

1.  **ê³µê° ë° ì •ì¤‘í•œ ì‘ë‹µ:** ì‚¬ìš©ìì˜ ë¶ˆí¸ì‚¬í•­ì— ëŒ€í•´ **ì •ì¤‘í•˜ê³  ê³µê° ì–´ë¦° ë§íˆ¬**ë¡œ ì‘ë‹µí•˜ë©°, ë¶ˆí¸ì„ ë¼ì³ë“œë¦° ì ì— ëŒ€í•´ ê¹Šì´ ì‚¬ê³¼í•©ë‹ˆë‹¤.
2.  **ë¬¸ì œ êµ¬ì²´í™” ë° ìˆ˜ì§‘:** ì‚¬ìš©ìê°€ ê²ªì€ ë°œìƒ ë¬¸ì œë¥¼ **êµ¬ì²´ì ìœ¼ë¡œ ì •ë¦¬**í•˜ì—¬ (ì˜ˆ: 'ë¬´ì—‡ì´', 'ì–¸ì œ', 'ì–´í”Œ ë‚´ ì–´ëŠ í…Œë§ˆ ë˜ëŠ” ê³¼ì •ì—ì„œ', 'ì–´ë–»ê²Œ') ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì´ë¥¼ ì–´í”Œ ìš´ì˜ ë° ê¸°ìˆ  ë‹´ë‹¹ìì—ê²Œ ì „ë‹¬í•˜ì—¬ **ì‹ ì†íˆ í•´ê²°í•˜ê² ë‹¤**ëŠ” ì·¨ì§€ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.
3.  **ì´ë©”ì¼ ìš”ì²­:** ë‹µë³€ì˜ ë§ˆì§€ë§‰ì—ëŠ” ë‹´ë‹¹ìê°€ ê²€í†  í›„ ì‹ ì†í•˜ê²Œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆë„ë¡ **ì—°ë½ ê°€ëŠ¥í•œ ì´ë©”ì¼ ì£¼ì†Œ**ë¥¼ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤.
4.  **ì´ë©”ì¼ ì œê³µ ê±°ë¶€ ì‹œ:** ë§Œì¼ ì‚¬ìš©ìê°€ ì—°ë½ ì œê³µì„ ì›ì¹˜ ì•Šìœ¼ë©´:
    "ê³ ê°ë‹˜ì˜ ê°œì¸ ì •ë³´ ë³´í˜¸ ì˜ì‚¬ë¥¼ ì¡´ì¤‘í•©ë‹ˆë‹¤. ë‹¤ë§Œ, ë‹´ë‹¹ìì˜ ìƒì„¸ ê²€í†  ë‚´ìš©ì„ ë³„ë„ë¡œ ì „ë‹¬ë“œë¦´ ë°©ë²•ì´ ì—†ì–´, ì´ ì  ì–‘í•´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."ë¼ê³  **ì •ì¤‘íˆ ì•ˆë‚´**í•©ë‹ˆë‹¤.
"""

# Gemini ì±„íŒ… ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_chat_session(api_key, model_name):
    """Gemini API í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•˜ê³  ìƒˆ ì±„íŒ… ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
    try:
        genai.configure(api_key=api_key)
        
        # ì•ˆì „ ì„¤ì • (í•„ìš” ì‹œ)
        safety_settings = [
            # ì ì ˆí•œ ì•ˆì „ ì„¤ì •ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:
            # {
            #     "category": HarmCategory.HARM_CATEGORY_HARASSMENT,
            #     "threshold": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            # }
        ]
        
        # Chat Session ìƒì„±
        model = genai.GenerativeModel(
            model_name=model_name,
            system_instruction=SYSTEM_PROMPT,
            # safety_settings=safety_settings  # ì•ˆì „ ì„¤ì • ì ìš©
        )
        # st.session_state.messagesëŠ” Streamlit ë©”ì‹œì§€ UI í‘œì‹œì— ì‚¬ìš©
        st.session_state.messages = [] 
        # model.start_chat()ì€ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë° API í˜¸ì¶œì— ì‚¬ìš©
        return model.start_chat(history=[])

    except Exception as e:
        st.error(f"Gemini API ì„¤ì • ë˜ëŠ” ì„¸ì…˜ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        st.stop()

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ë° ì±„íŒ… ì„¸ì…˜ ê´€ë¦¬
if "chat" not in st.session_state:
    st.session_state.chat = initialize_chat_session(GEMINI_API_KEY, selected_model)
    st.session_state.messages = [] # Streamlit UIìš© ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    st.session_state.history_reset_count = 0 # 429 ì¬ì‹œë„ ì¹´ìš´íŠ¸ìš©
    
# --- ëŒ€í™” íˆìŠ¤í† ë¦¬ CSV ë¡œê¹… í•¨ìˆ˜ ---
LOG_FILE_PATH = "chat_log.csv"

def log_to_csv(role, content):
    """ëŒ€í™” ë‚´ìš©ì„ CSV íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤."""
    if not st.session_state.log_to_csv:
        return

    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    # ëª¨ë¸ëª…ê³¼ ì„¸ì…˜ ì •ë³´ ì¶”ê°€ (ì´ˆê¸°í™” íšŸìˆ˜ë¡œ ì„¸ì…˜ êµ¬ë¶„)
    session_info = f"{st.session_state.model_select}_{st.session_state.history_reset_count}"
    
    new_entry = pd.DataFrame([{
        "Timestamp": timestamp,
        "Session": session_info,
        "Role": role,
        "Content": content.replace('\n', ' ') # ì¤„ë°”ê¿ˆ ì œê±°í•˜ì—¬ CSVì— ê¹”ë”í•˜ê²Œ ê¸°ë¡
    }])
    
    # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , í—¤ë” ì¶”ê°€ ì—¬ë¶€ ê²°ì •
    if os.path.exists(LOG_FILE_PATH):
        new_entry.to_csv(LOG_FILE_PATH, mode='a', header=False, index=False)
    else:
        new_entry.to_csv(LOG_FILE_PATH, mode='w', header=True, index=False)

# --- 429 ì¬ì‹œë„ ë° ëŒ€í™” ìœ ì§€ ë¡œì§ ---

def get_response_with_retry(prompt, model_name, max_retries=3):
    """
    Gemini APIë¥¼ í˜¸ì¶œí•˜ê³  429 ì—ëŸ¬ ë°œìƒ ì‹œ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì •ë¦¬ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.
    ìµœê·¼ 6í„´(User 3, Assistant 3)ì„ ìœ ì§€í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤.
    """
    current_chat_history = st.session_state.chat.history
    
    for attempt in range(max_retries):
        try:
            # API í˜¸ì¶œ
            response = st.session_state.chat.send_message(prompt, stream=True)
            return response
        
        except genai.errors.ResourceExhaustedError as e:
            # 429 ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬
            st.warning(f"âš ï¸ API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ(429) ë°œìƒ. ({attempt + 1}/{max_retries} ì¬ì‹œë„ ì¤‘...)")
            
            if attempt < max_retries - 1:
                # ìµœê·¼ 6í„´(User 3, Assistant 3)ë§Œ ë‚¨ê¸°ê³  íˆìŠ¤í† ë¦¬ ì •ë¦¬ í›„ ì¬ì‹œë„
                
                # Streamlit UI ë©”ì‹œì§€ì—ì„œë„ ìµœê·¼ 6ê°œë§Œ ë‚¨ê¹€
                st.session_state.messages = st.session_state.messages[-6:]
                
                # Gemini Chat.historyì—ì„œ ìµœê·¼ 6ê°œì˜ Partë§Œ ë‚¨ê¹€
                # st.session_state.chat.historyëŠ” Content ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸ì´ë©°, ê° ContentëŠ” Parts ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì§.
                # ContentëŠ” roleê³¼ partsë¡œ êµ¬ì„±ë¨.
                if len(current_chat_history) > 6:
                    st.session_state.chat.history = current_chat_history[-6:]
                    
                # Chat ì„¸ì…˜ì„ ì•„ì˜ˆ ì¬ì‹œì‘ (íˆìŠ¤í† ë¦¬ ì •ë¦¬ íš¨ê³¼)
                st.session_state.chat = initialize_chat_session(GEMINI_API_KEY, model_name)
                # ìƒˆë¡œìš´ ì´ˆê¸°í™” íšŸìˆ˜ ê¸°ë¡ (ì„¸ì…˜ êµ¬ë¶„ìš©)
                st.session_state.history_reset_count += 1
                
                # ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
                st.info("ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ê¸¸ì–´ì ¸ ìµœê·¼ 3ë²ˆì˜ ì§ˆë¬¸/ë‹µë³€ë§Œ ë‚¨ê¸°ê³  ì„¸ì…˜ì„ ì¬ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")
                time.sleep(2) # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                continue # ë‹¤ìŒ ì‹œë„ë¡œ ë„˜ì–´ê° (ì´ ì‹œì ì—ì„œ ìœ ì €ì˜ í”„ë¡¬í”„íŠ¸ëŠ” ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ë‹¤ì‹œ send_messageë¥¼ ì‹œë„í•´ì•¼ í•¨)
            
            else:
                # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
                st.error("API í˜¸ì¶œ íšŸìˆ˜ ì œí•œì´ ê³„ì† ë°œìƒí•˜ì—¬ ë” ì´ìƒ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                st.session_state.messages.append({"role": "assistant", "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ìš”ì²­ ê³¼ë¶€í•˜ë¡œ ì¸í•´ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹­ì‹œì˜¤."})
                return None
        
        except Exception as e:
            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.session_state.messages.append({"role": "assistant", "content": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹­ì‹œì˜¤."})
            return None
    
    # max_retriesë¥¼ ëª¨ë‘ ì†Œì§„í•˜ê³ ë„ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆì„ ê²½ìš°
    return None

# --- UI ë° ì£¼ìš” ë¡œì§ ---

# í˜„ì¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë¶ˆí¸í•˜ì‹  ë‚´ìš©ì„ ì•Œë ¤ì£¼ì‹œë©´ ì‹ ì†í•˜ê²Œ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤."):
    
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
        
    log_to_csv("user", prompt) # CSV ë¡œê¹…
    
    # 2. AI ì‘ë‹µ ìƒì„± ë° ì²˜ë¦¬
    with st.chat_message("assistant"):
        
        # 429 ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ì‘ë‹µ ìƒì„±
        response_stream = get_response_with_retry(prompt, selected_model)
        
        if response_stream:
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì»¨í…Œì´ë„ˆ
            placeholder = st.empty()
            full_response = ""
            
            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°
            for chunk in response_stream:
                if chunk.text:
                    full_response += chunk.text
                    placeholder.markdown(full_response + "â–Œ") # ì»¤ì„œ íš¨ê³¼
            
            placeholder.markdown(full_response) # ìµœì¢… ì‘ë‹µ í‘œì‹œ
            
            # 3. AI ì‘ë‹µ íˆìŠ¤í† ë¦¬ ê¸°ë¡ ë° CSV ë¡œê¹…
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            log_to_csv("assistant", full_response) # CSV ë¡œê¹…

# --- ì‚¬ì´ë“œë°” ì¶”ê°€ ê¸°ëŠ¥ ---

# ëª¨ë¸/ì„¸ì…˜ í‘œì‹œ
st.sidebar.markdown("---")
st.sidebar.subheader("â„¹ï¸ í˜„ì¬ ìƒíƒœ")
st.sidebar.markdown(f"**ëª¨ë¸:** `{selected_model}`")
st.sidebar.markdown(f"**ì„¸ì…˜ êµ¬ë¶„:** `RST: {st.session_state.history_reset_count}`")

# ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
if os.path.exists(LOG_FILE_PATH):
    with open(LOG_FILE_PATH, "rb") as file:
        st.sidebar.download_button(
            label="â¬‡ï¸ ëŒ€í™” ë¡œê·¸ (CSV) ë‹¤ìš´ë¡œë“œ",
            data=file,
            file_name=LOG_FILE_PATH,
            mime="text/csv"
        )
else:
    st.sidebar.info("ì €ì¥ëœ ëŒ€í™” ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")